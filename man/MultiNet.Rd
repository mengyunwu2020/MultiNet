% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MultiNet.R
\name{MultiNet}
\alias{MultiNet}
\title{Estimation of multiple networks with common structures in heterogeneous subgroups (MultiNet).}
\usage{
MultiNet(
  data,
  K,
  lambda.lasso,
  lambda.similar,
  eps = 0.001,
  niter = 100,
  initialization = "K-means",
  initialize,
  beta = NULL,
  traces = FALSE,
  tau.theta = 0.001,
  refit = TRUE,
  n.start = NULL,
  re = 1
)
}
\arguments{
\item{data}{An n by p data matrix.}

\item{K}{Number of clusters.}

\item{lambda.lasso}{Penalty parameter for lasso term.}

\item{lambda.similar}{Penalty parameter for group item.}

\item{eps}{Tolerance for the EM algorithm. The default value is 1e-3.}

\item{niter}{Maximum number of iterations.}

\item{initialization}{The method of initialization. Can be "k-means". Otherwise, it must be initialized with the initialize parameter.}

\item{initialize}{A list, which includes the initialization values of Theta, Mu and prob.}

\item{beta}{(p-1)*K by p Matrix of initialized regression coefficients. Default is NULL.}

\item{traces}{Whether to trace intermediate results.}

\item{tau.theta}{Threshold parameter for precision matrix.}

\item{refit}{Whether to perform the refit process after the EM algorithm converges.}

\item{n.start}{The parameter in k-means initialization, indicating how many random sets should be selected.}

\item{re}{The seed used in the initialization step.}
}
\value{
a list with entries
\item{mu}{Estimated mean matrix. }
\item{Theta}{Array of estimated precision matrices. }
\item{prob}{A vector of estimated probabilities. }
\item{L.mat}{n by K Matrix of estimated probability that each sample belongs to each subgroup. }
\item{member}{A vector representing the estimated membership of each sample. }
\item{beta}{(p-1)*K by p Matrix of estimated regression coefficients. }
}
\description{
Estimation of multiple networks with common structures in heterogeneous subgroups (MultiNet).
}
\details{
This function estimates multiple networks based on SQRT-sparse group lasso.
}
\examples{
n <- 200              # The sample size of each subgroup
p <- 100              # The dimension of the precision matrix
K0 <- 3
mue <- .8
nonnum <- 2
mu01 <- c(rep(mue,nonnum),rep(-mue,nonnum),rep(-0,p-2*nonnum))
mu02 <- c(rep(mue,2*nonnum),rep(-0,p-2*nonnum))
mu03 <- c(rep(-mue,2*nonnum),rep(-0,p-2*nonnum))
num.differ=8
N <- rep(n,K0)
A.list <- Power.law.network(p,s=10,umin=0.3,umax=0.6,num.differ=num.differ)
Theta01 <- A.list$A1
Theta02 <- A.list$A2
Theta03 <- A.list$A3
sigma01 <- solve(Theta01)
sigma02 <- solve(Theta02)
sigma03 <- solve(Theta03)
Mu0.list <- list(mu01,mu02,mu03)
Sigma0.list <- list(sigma01,sigma02,sigma03)
Theta0.list <- list(Theta01,Theta02,Theta03)
set.seed(1)
whole.data <- generate.data(N,Mu0.list,Theta0.list,Sigma0.list)
lambda <- list()
opt=sqrt(log(p-1))/sqrt(nrow(whole.data$data)*K0)
opt2=sqrt(log((p-1)*K0))/sqrt(nrow(whole.data$data)*K0)
lambda$lambda.similar=0.05*opt
lambda$lambda.lasso=0.1*opt2
res<-MultiNet(whole.data$data,K0,lambda$lambda.lasso,lambda$lambda.similar)
}
